{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes about 5 mins to run\n",
    "\n",
    "res = requests.get(\"https://classes.cornell.edu/api/2.0/search/classes.json?roster=SP18&subject=AEM\")\n",
    "\n",
    "res_json = res.json() # Is now a dict\n",
    "\n",
    "class_roster_api_dict = defaultdict(lambda : {\"professors\":set(), \n",
    "                                              \"subject-number\": set(),\n",
    "                                              \"semesters\": set()})\n",
    "\n",
    "col_mappings = {\"crseId\":\"id\",\n",
    "               \"titleLong\" : \"title\",\n",
    "               \"description\" : \"description\",\n",
    "               \"catalogOutcomes\" : \"outcomes\"}\n",
    "\n",
    "# semesters = [\"FA20\"]\n",
    "semesters = [\"SP20\", \"FA19\", \"SP19\", \"FA18\", \"SP18\"]\n",
    "semesters = [\"SP20\"]\n",
    "\n",
    "\n",
    "\n",
    "# Get list of subjects (majors) taught during these semesters\n",
    "\n",
    "subjects = set() \n",
    "\n",
    "for semester in semesters:\n",
    "    for subject in requests.get(\"https://classes.cornell.edu/api/2.0/config/subjects.json?roster=\"+semester)\\\n",
    "                    .json()[\"data\"][\"subjects\"]:\n",
    "        subjects.add(subject[\"value\"])\n",
    "\n",
    "        \n",
    "for semester in semesters:            \n",
    "    for subject in tqdm(subjects):\n",
    "        res = requests.get(\"https://classes.cornell.edu/api/2.0/search/classes.json?roster=\" \n",
    "                           + semester + \"&subject=\" + subject)\n",
    "        if(res.json()[\"data\"] is not None and res.json()[\"data\"][\"classes\"] is not None):\n",
    "            for res_class in res.json()[\"data\"][\"classes\"]:\n",
    "                professors = set()\n",
    "                \n",
    "                course_id = str(res_class[\"crseId\"])\n",
    "                \n",
    "                if(res_class[\"enrollGroups\"] is not None):\n",
    "                    for section in res_class[\"enrollGroups\"][0][\"classSections\"]:\n",
    "                        for meeting in section[\"meetings\"]:\n",
    "                            for professor in meeting[\"instructors\"]:\n",
    "                                professors.add(\" \".join([professor[\"firstName\"], \n",
    "                                                          professor[\"middleName\"], \n",
    "                                                          professor[\"lastName\"]]))\n",
    "                        \n",
    "                for prof in professors:\n",
    "                    class_roster_api_dict[course_id][\"professors\"].add(prof)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                class_roster_api_dict[course_id][\"subject-number\"].add(\" \".join([res_class[\"subject\"], \n",
    "                                                                       str(res_class[\"catalogNbr\"])]))\n",
    "                \n",
    "                class_roster_api_dict[course_id][\"semesters\"].add(semester)\n",
    "                if(\"description\" not in class_roster_api_dict[course_id]\n",
    "                   or (\"description\" in class_roster_api_dict[course_id]\n",
    "                          and class_roster_api_dict[course_id][\"description\"] == \"\")):\n",
    "                    for catalogKey, dictKey in col_mappings.items():\n",
    "                        class_roster_api_dict[course_id][dictKey] = res_class[catalogKey]\n",
    "                    if(class_roster_api_dict[course_id][\"outcomes\"] == None):\n",
    "                        class_roster_api_dict[course_id][\"outcomes\"] = \"\"\n",
    "                    else:\n",
    "                        class_roster_api_dict[course_id][\"outcomes\"] = \" \".join(\n",
    "                            class_roster_api_dict[course_id][\"outcomes\"])\n",
    "                   \n",
    "                    if(class_roster_api_dict[course_id][\"description\"] == None):\n",
    "                        class_roster_api_dict[course_id][\"description\"] = \"\"\n",
    "    \n",
    "def get_latest_sem(sems):\n",
    "    return sorted(sems, key=lambda sem:(-int(sem[2:]), sem[0:2]))[0]\n",
    "\n",
    "for key in class_roster_api_dict.keys():\n",
    "    c = class_roster_api_dict[key]\n",
    "    latest_sem = get_latest_sem(list(c[\"semesters\"]))\n",
    "    subject, number = list(c[\"subject-number\"])[0].split()\n",
    "    url = \"https://classes.cornell.edu/browse/roster/\"+ latest_sem+\"/class/\"+subject.upper()+\"/\"+number\n",
    "    class_roster_api_dict[key][\"roster_url\"] = url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condense cross-listed upper level classes\n",
    "# E.g CS 4670 and CS 5670\n",
    "title_dict = defaultdict(set)\n",
    "\n",
    "for key in class_roster_api_dict.keys():\n",
    "    title = class_roster_api_dict[key][\"title\"]\n",
    "    title_dict[title].add(key)\n",
    "\n",
    "for title in title_dict.keys():\n",
    "    min_id = min(title_dict[title])\n",
    "    for id in title_dict[title]:\n",
    "        if(id != min_id):\n",
    "            for s in [\"professors\", \"subject-number\", \"semesters\"]:\n",
    "                class_roster_api_dict[min_id][s] = class_roster_api_dict[min_id][s].union(class_roster_api_dict[id][s])\n",
    "            del class_roster_api_dict[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate URLs for each class\n",
    "\n",
    "def get_latest_sem(sems):\n",
    "    return sorted(sems, key=lambda sem:(-int(sem[2:]), sem[0:2]))[0]\n",
    "\n",
    "for key in class_roster_api_dict.keys():\n",
    "    c = class_roster_api_dict[key]\n",
    "    latest_sem = get_latest_sem(list(c[\"semesters\"]))\n",
    "    subject, number = list(c[\"subject-number\"])[0].split()\n",
    "    url = \"https://classes.cornell.edu/browse/roster/\"+ latest_sem+\"/class/\"+subject.upper()+\"/\"+number\n",
    "    class_roster_api_dict[key][\"roster_url\"] = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'professors': {'David Joseph Gries', 'Anne  Bracy', 'Eleanor Jane Birrell', 'Michael Ryan Clarkson'}, 'subject-number': {'ENGRD 2110', 'CS 2110'}, 'semesters': {'SP19', 'SP18', 'FA19', 'SP20', 'FA18'}, 'id': 358546, 'title': 'Object-Oriented Programming and Data Structures', 'description': 'Intermediate programming in a high-level language and introduction to computer science. Topics include object-oriented programming (classes, objects, subclasses, types), graphical user interfaces, algorithm analysis (asymptotic complexity, big \"O\" notation), recursion, testing, program correctness (loop invariants), searching/sorting, data structures (lists, trees, stacks, queues, heaps, search trees, hash tables, graphs), graph algorithms. Java is the principal programming language.', 'outcomes': 'Be fluent in the use of recursion and object-oriented programming concepts (e.g. classes, objects, inheritance, and interfaces). Be able to design and implement nontrivial Java programs (roughly 1000 lines of code), starting from an English language specification. Understand graphical user interfaces (GUIs), as expressed in Java. Understand asymptotic complexity of algorithms and be able to analyze programs to determine their running times. Understand basic data structures taught in the course and be able to implement them and use them in programs.', 'roster_url': 'https://classes.cornell.edu/browse/roster/SP20/class/ENGRD/2110'}\n",
      "\n",
      "{'professors': {'Bharath  Hariharan'}, 'subject-number': {'CS 4670', 'CS 5670'}, 'semesters': {'SP19', 'SP18', 'SP20'}, 'id': 363853, 'title': 'Introduction to Computer Vision', 'description': 'An in-depth introduction to computer vision. The goal of computer vision is to compute properties of our world-the 3D shape of an environment, the motion of objects, the names of people or things-through analysis of digital images or videos. \\xa0The course covers a range of topics, including 3D reconstruction, image segmentation, object recognition, and vision algorithms fro the Internet, as well as key algorithmic, optimization, and machine learning techniques, such as graph cuts, non-linear least squares, and deep learning. \\xa0This course emphasizes hands-on experience with computer vision, and several large programming projects.', 'outcomes': '', 'roster_url': 'https://classes.cornell.edu/browse/roster/SP20/class/CS/4670'}\n"
     ]
    }
   ],
   "source": [
    "# Quick test for CS 2110 and CS 4670:\n",
    "\n",
    "print([class_roster_api_dict[key] for key in class_roster_api_dict.keys() \n",
    " if \"CS 2110\" in class_roster_api_dict[key][\"subject-number\"]][0])\n",
    "\n",
    "print()\n",
    "\n",
    "print([class_roster_api_dict[key] for key in class_roster_api_dict.keys() \n",
    " if \"CS 4670\" in class_roster_api_dict[key][\"subject-number\"]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write classes to pickle\n",
    "\n",
    "# Convert defaultdict to dict\n",
    "\n",
    "pickle.dump(dict(class_roster_api_dict), open(\"class_roster_api_dict.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate average length of descriptions by major\n",
    "# DEPRECATED CODE, was used just for P01 stats\n",
    "\n",
    "subject_desc_len = dict()\n",
    "\n",
    "for subject in subjects:\n",
    "    sum_words = 0\n",
    "    for index, row in classes_df[classes_df[\"subject\"] == subject].iterrows():\n",
    "        if(row[\"description\"] is not None):\n",
    "            sum_words += len(row[\"description\"].split())\n",
    "        \n",
    "    if(len(classes_df[classes_df[\"subject\"] == subject]) > 0):\n",
    "        subject_desc_len[subject] = sum_words / len(classes_df[classes_df[\"subject\"] == subject])\n",
    "    else:\n",
    "        subject_desc_len[subject] = 0\n",
    "    \n",
    "# for key in subject_desc_len.keys():\n",
    "#     print(key + \",\" + str(subject_desc_len[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_professor_page(professor):\n",
    "    professor = professor.replace(\", Professor\", \"\")\n",
    "    url = \"https://www.ratemyprofessors.com/search.jsp?queryoption=HEADER&\" \\\n",
    "          \"queryBy=teacherName&schoolID=%s&query=\" % str(298) + \"+\".join(professor.split())\n",
    "    page = requests.get(url=url)\n",
    "    pageData = page.text\n",
    "    pageDataTemp = re.findall(r'ShowRatings\\.jsp\\?tid=\\d+', pageData)\n",
    "    if(len(pageDataTemp) > 0):\n",
    "        pageDataTemp = re.findall(r'ShowRatings\\.jsp\\?tid=\\d+', pageData)[0]\n",
    "        finalUrl = \"https://www.ratemyprofessors.com/\" + pageDataTemp\n",
    "        page = requests.get(finalUrl)\n",
    "        \n",
    "        return page\n",
    "    \n",
    "    elif(len(professor.split()) > 3):\n",
    "        page = get_professor_page(\" \".join([professor.split()[0], professor.split()[3]]))\n",
    "        if(page == None):\n",
    "            page = get_professor_page(\" \".join([professor.split()[0],\n",
    "                                                 professor.split()[1],\n",
    "                                                 professor.split()[3]]))\n",
    "        if(page == None):\n",
    "            page = get_professor_page(\" \".join([professor.split()[0],\n",
    "                                                 professor.split()[2],\n",
    "                                                 professor.split()[3]]))\n",
    "    elif(len(professor.split()) > 2):\n",
    "        page = get_professor_page(\" \".join([professor.split()[0],professor.split()[2]]))\n",
    "        if(page == None):\n",
    "            page = get_professor_page(\" \".join([professor.split()[0], professor.split()[2]]))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return page\n",
    "\n",
    "def get_professor_tags(page, tags_default):\n",
    "    \n",
    "    tags = tags_default\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    school = soup.find(class_=\"NameTitle__Title-dowf0z-1\")\n",
    "    if(school is not None):\n",
    "        school_split = school.text.split(\"at \")\n",
    "        if(len(school_split) > 1 and school_split[1] != \"Cornell University\"):\n",
    "            return tags\n",
    "        \n",
    "    tags_list = soup.find(class_='TeacherTags__TagsContainer-sc-16vmh1y-0')\n",
    "    tags = []\n",
    "    if(tags_list is not None):\n",
    "        spans = tags_list.findAll(\"span\")\n",
    "        if(len(spans) > 0):\n",
    "            tags = [d.text for d in spans]\n",
    "            \n",
    "    return tags\n",
    "        \n",
    "        \n",
    "def get_professor_top_review(page, review_default):\n",
    "    review = review_default\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    school = soup.find(class_=\"NameTitle__Title-dowf0z-1\")\n",
    "    if(school is not None):\n",
    "        school_split = school.text.split(\"at \")\n",
    "        if(len(school_split) > 1 and school_split[1] != \"Cornell University\"):\n",
    "            return review\n",
    "\n",
    "    most_helpful_review = soup.find(class_='HelpfulRating__StyledComments-sc-4ngnti-1')\n",
    "\n",
    "    if(most_helpful_review is not None):\n",
    "        review = most_helpful_review.text\n",
    "\n",
    "    if(review == \"\"):\n",
    "        review_list = soup.findAll(class_='Comments__StyledComments-dzzyvm-0')[:5]\n",
    "        review = \" \".join([d.text for d in review_list])\n",
    "            \n",
    "    return review\n",
    "        \n",
    "def get_professor_rating(page, rating_default):\n",
    "    rating = rating_default\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    school = soup.find(class_=\"NameTitle__Title-dowf0z-1\")\n",
    "    if(school is not None):\n",
    "        school_split = school.text.split(\"at \")\n",
    "        if(len(school_split) > 1 and school_split[1] != \"Cornell University\"):\n",
    "            return rating\n",
    "\n",
    "    rating = str(soup.find(class_='RatingValue__Numerator-qw8sqy-2').text)\n",
    "    \n",
    "    if(rating != \"N/A\"):\n",
    "        rating = float(rating)\n",
    "    else:\n",
    "        rating = rating_default\n",
    "        \n",
    "    return rating\n",
    "\n",
    "def get_professor_stat(page, default_return, scraping_function):\n",
    "    \n",
    "    if(page == None):\n",
    "        return default_return\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    school = soup.find(class_=\"NameTitle__Title-dowf0z-1\")\n",
    "    if(school is not None):\n",
    "        school_split = school.text.split(\"at \")\n",
    "        if(len(school_split) > 1 and school_split[1] != \"Cornell University\"):\n",
    "            return default_return\n",
    "\n",
    "    return scraping_function(page, default_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_set = set()\n",
    "for entry in class_roster_api_dict.keys():\n",
    "    for prof in class_roster_api_dict[entry][\"professors\"]:\n",
    "        prof_set.add(prof)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This cell takes 2-2.5 hours to run!!\n",
    "\n",
    "# It scrapes from RateMyProfessor.com\n",
    "\n",
    "ratemyprofessor_api_dict = dict()\n",
    "\n",
    "for prof in tqdm(list(prof_set)):\n",
    "    page = get_professor_page(prof)\n",
    "    rating = get_professor_stat(page, None, get_professor_rating)\n",
    "    if(rating is None):\n",
    "            page = None\n",
    "    review = get_professor_stat(page, None, get_professor_top_review)\n",
    "    tags = get_professor_stat(page, [], get_professor_tags)\n",
    "    \n",
    "    \n",
    "    ratemyprofessor_api_dict[prof] = {\"review\":review, \"rating\": rating, \"tags\": tags}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the professors that have a RateMyProfessor review and tags \n",
    "\n",
    "ratemyprofessor_api_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write professors to CSV\n",
    "\n",
    "#Write ratemyprofessor data to pickle\n",
    "\n",
    "# Convert defaultdict to dict\n",
    "\n",
    "pickle.dump(ratemyprofessor_api_dict, open(\"ratemyprofessor_api_dict.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
